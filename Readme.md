ğŸ” Retrieval Integrity Auditor for RAG Systems

A retrieval-focused audit framework for evaluating the quality, completeness, and trustworthiness of document retrieval in Retrieval-Augmented Generation (RAG) pipelines.

This system evaluates retrieval quality independently of answer generation, ensuring that downstream LLM outputs are based on correct, complete, and low-noise evidence.

ğŸš¨ Why This Matters

RAG systems often appear correct because LLMs generate fluent answers.
However, retrieval failures are frequently hidden, leading to:

Missing critical evidence

Irrelevant or noisy documents influencing answers

Compliance and decision-making risks

Over-reliance on top-1 similarity results

This project addresses that gap by auditing retrieval before generation.

ğŸ¯ Core Objectives

Audit retrieved documents for coverage and relevance

Detect noise and irrelevant retrievals

Evaluate retrieval against ground truth evidence

Produce a retrieval integrity score (0â€“100)

Generate machine-readable and human-readable audit reports

Keep the system simple, explainable, and extensible

âœ¨ Key Features
1ï¸âƒ£ Coverage Analysis

Measures how much required evidence is retrieved

Detects incomplete or partial retrieval

Highlights potential missing evidence

2ï¸âƒ£ Noise Detection

Identifies irrelevant or off-topic documents

Computes noise ratio and retrieval precision

Penalizes noisy retrieval behavior

3ï¸âƒ£ Ground Truth Evaluation

Compares retrieved documents with labeled relevant documents

Computes:

Precision

Recall

Enables objective offline evaluation

4ï¸âƒ£ Retrieval Integrity Scoring

Composite score (0â€“100) based on:

Coverage

Noise penalty

Clear PASS / FAIL gating logic

5ï¸âƒ£ Explainable Reporting

Human-readable console output

Machine-readable JSON report

Clear justification for FAIL cases

ğŸ§  What This System Is (and Is Not)
âœ… This System IS

A retrieval quality auditor

Independent of LLM answer generation

Explainable and evaluation-driven

Suitable for enterprise RAG validation

âŒ This System Is NOT

A chatbot

A trained ML model

A full production RAG platform

An answer generation engine

ğŸ—‚ï¸ Project Structure
rag_retrieval_audit/
â”‚
â”œâ”€â”€ main.py                 # Orchestrates the full audit pipeline
â”œâ”€â”€ retrieve.py             # Semantic retrieval using embeddings
â”œâ”€â”€ analyze.py              # Coverage and noise analysis
â”œâ”€â”€ evaluate.py             # Precision & recall (ground truth)
â”œâ”€â”€ score.py                # Integrity score calculation
â”œâ”€â”€ report.py               # JSON + console report generation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents.json      # Knowledge base documents
â”‚   â”œâ”€â”€ queries.json        # Input queries
â”‚   â””â”€â”€ ground_truth.json   # Expected relevant documents
â”‚
â””â”€â”€ output/
    â””â”€â”€ audit_report.json   # Final audit output

ğŸ”„ System Workflow
User Query
   â†“
Semantic Retrieval (Embeddings)
   â†“
Coverage & Noise Analysis
   â†“
Ground Truth Evaluation
   â†“
Integrity Scoring
   â†“
Audit Report (JSON + Console)

ğŸ“Š Metrics Explained
Metric	Description
Coverage	% of required evidence retrieved
Precision	% of retrieved documents that are relevant
Recall	% of relevant documents retrieved
Noise Ratio	% of retrieved documents that are irrelevant
Integrity Score	Overall retrieval quality (0â€“100)
Status	PASS / FAIL decision
âœ… PASS vs FAIL Logic
Score â‰¥ 60 â†’ PASS (retrieval is trustworthy)
Score < 60 â†’ FAIL (retrieval is risky)


A FAIL does not mean the system is broken.
It indicates retrieval quality is insufficient for safe generation.

ğŸ“ Data Format
documents.json
[
  {
    "doc_id": "D1",
    "text": "GDPR defines rules for data protection and privacy in the EU."
  }
]

queries.json
{
  "query_id": "q1",
  "query": "What is GDPR data retention policy for financial records?"
}

ground_truth.json
{
  "q1": ["D1", "D2"]
}

â–¶ï¸ How to Run
1ï¸âƒ£ Install Dependencies
pip install sentence-transformers scikit-learn

2ï¸âƒ£ Run the Audit
python main.py

ğŸ§¾ Sample Output (Console)
=== RETRIEVAL INTEGRITY AUDIT ===
Query: What is GDPR data retention policy for financial records?
Score: 60/100
Coverage: 100.0%
Precision: 0.67
Recall: 1.0
Noise Ratio: 33.33%
Status: PASS

ğŸ“„ Sample Output (audit_report.json)
{
  "query": "What is GDPR data retention policy for financial records?",
  "score": 60,
  "coverage": 100.0,
  "precision": 0.67,
  "recall": 1.0,
  "noise_ratio": 33.33,
  "status": "PASS"
}